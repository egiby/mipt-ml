{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def read_data(filename, labels, types, sep=None):\n",
    "    data = dict()\n",
    "    for label in labels:\n",
    "        data[label] = []\n",
    "    \n",
    "    with open(filename) as fin:\n",
    "        for line in fin:\n",
    "            keys = []\n",
    "            if sep is None:\n",
    "                keys = line.split()\n",
    "            else:\n",
    "                keys = line.split(sep)\n",
    "            \n",
    "            for key, label, ttype in zip(keys, labels, types):\n",
    "                data[label].append(ttype(key))\n",
    "            \n",
    "    data['size'] = len(data[labels[0]])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = '../../data/linear_contest1/'\n",
    "raw_data = read_data(prefix + 'linear_train.txt', ['words', 'y'], [str, int], sep=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем признаки и обрабатываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_by_indices(data, indices):\n",
    "    new_data = dict()\n",
    "    new_data['size'] = len(indices)\n",
    "    \n",
    "    for key, feature in data.items():\n",
    "        if key == 'size':\n",
    "            continue\n",
    "        new_data[key] = np.array(data[key])[list(indices)]\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "\n",
    "def sample(data, frac, random_state):  # data must have key 'size'\n",
    "    np.random.seed(random_state)\n",
    "    indices = set()\n",
    "    N = int(data['size'] * frac)\n",
    "    \n",
    "    while len(indices) < N:\n",
    "        indices.add(np.random.randint(0, data['size']))\n",
    "    \n",
    "    return get_by_indices(data, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10140"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac = .1\n",
    "\n",
    "train_sample = sample(raw_data, frac=frac, random_state=501)\n",
    "\n",
    "train_sample['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def gen_features(sample, ngram_range=(1, 4), n_features=2 ** 20):\n",
    "    hashes = HashingVectorizer(ngram_range=ngram_range, \n",
    "                               analyzer='char_wb', \n",
    "                               n_features=n_features,\n",
    "                               norm='l2').fit_transform(sample['words'])\n",
    "    new_sample = dict(sample)\n",
    "    new_sample['features'] = hashes\n",
    "    return new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': <10140x1048576 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 267156 stored elements in Compressed Sparse Row format>,\n",
       " 'size': 10140,\n",
       " 'words': array(['Аалтонен', 'Катон', 'шпиля', ..., 'прегрешениями', 'католиков',\n",
       "        'ПРЕДАНИЯМИ'], \n",
       "       dtype='<U33'),\n",
       " 'y': array([1, 1, 0, ..., 0, 0, 0])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_features(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "def roc_auc(y, y_pred):\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_pred, y)\n",
    "    return metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "def cross_validation(model, data, n_splits=5, **kwargs):\n",
    "    score = 0.\n",
    "    for train_indices, test_indices in KFold(n_splits=n_splits).split(data['y']):\n",
    "        train = get_by_indices(data, train_indices)\n",
    "        test = get_by_indices(data, test_indices)\n",
    "        train = gen_features(train, **kwargs)\n",
    "        test = gen_features(test, **kwargs)\n",
    "        model.fit(train['features'], train['y'])\n",
    "        score += roc_auc(model.predict_proba(test['features'])[:, 1], test['y'])\n",
    "    \n",
    "    return score / n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825149396621\n",
      "CPU times: user 5.57 s, sys: 413 ms, total: 5.99 s\n",
      "Wall time: 6.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(cross_validation(LogisticRegression(random_state=501, n_jobs=3, C=5.3, dual=True), \n",
    "                       train_sample,\n",
    "                       ngram_range=(1, 6),\n",
    "                       n_features=2 ** 24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8603 -- full\n",
    "\n",
    "0.8251 -- train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5 0.860250065813\n",
      "4.7 0.860282890746\n",
      "4.9 0.86030857431\n",
      "5.1 0.860323012747\n",
      "5.3 0.860328173249\n",
      "5.5 0.860324542475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "for C in np.arange(5., 5.51, 0.1):\n",
    "    print(C, cross_validation(LogisticRegression(random_state=501, n_jobs=3, C=C, dual=True), \n",
    "                              raw_data,\n",
    "                              ngram_range=(1, 6),\n",
    "                              n_features=2 ** 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 0.859911334715\n",
      "23 0.859995023475\n",
      "24 0.860021728912\n",
      "25 0.859972504041\n"
     ]
    }
   ],
   "source": [
    "for i in range(22, 26):\n",
    "    print(i, cross_validation(LogisticRegression(random_state=501, n_jobs=3, C=3.8, dual=True), \n",
    "                              raw_data,\n",
    "                              ngram_range=(1, 6),\n",
    "                              n_features=2 ** i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=3)]: Done 150 out of 150 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.81800827719452041, {'C': 2.0000000000000009, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.8183958393179217, {'C': 1.6000000000000005, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.82574306968175415, {'C': 1.3000000000000003, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.82749149731093952, {'C': 1.5000000000000004, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.84174974507011713, {'C': 1.4000000000000004, 'penalty': 'l2', 'random_state': 501})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model = LogisticRegression()\n",
    "clf = GridSearchCV(model, \n",
    "                   {\n",
    "                       'random_state': (501,), \n",
    "                       'C': np.arange(1, 6, 0.1),\n",
    "                       'penalty': ('l2',)\n",
    "                   }, \n",
    "                   n_jobs=3,\n",
    "                   scoring=make_scorer(roc_auc),\n",
    "                   verbose=1)\n",
    "\n",
    "data = gen_features(train_sample, ngram_range=(1, 4))\n",
    "clf.fit(data['features'], data['y'])\n",
    "\n",
    "print(*sorted(list(zip(clf.cv_results_['mean_test_score'], clf.cv_results_['params'])), \n",
    "              key=lambda x: x[0])[-5:], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.76156287049395088, {'C': 5.3000000000000043, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.76215475423129719, {'C': 5.5000000000000036, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.76316474013881208, {'C': 5.4000000000000039, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.76431691384592904, {'C': 1.0, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.76761605604853467, {'C': 1.1000000000000001, 'penalty': 'l2', 'random_state': 501})\n"
     ]
    }
   ],
   "source": [
    "print(*sorted(list(zip(clf.cv_results_['mean_test_score'], clf.cv_results_['params'])), \n",
    "              key=lambda x: x[0])[-5:], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Для отправки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prefix = '../../data/linear_contest1/'\n",
    "raw_data = read_data(prefix + 'linear_train.txt', ['words', 'y'], [str, int], sep=', ')\n",
    "raw_test = read_data(prefix + 'linear_test.txt', ['words'], [str])\n",
    "sample_submission = pd.read_csv(prefix + 'linear_ans_example.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=5.3, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=3,\n",
      "          penalty='l2', random_state=501, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "CPU times: user 10.6 s, sys: 96.7 ms, total: 10.7 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# M = 25\n",
    "# M = 15\n",
    "# model = RandomForestClassifier(n_estimators=150, n_jobs=3, random_state=501)\n",
    "# model = SVC(probability=True, random_state=501)\n",
    "C = 5.3\n",
    "ngram_range = (1, 6)\n",
    "n_features = 2 ** 24\n",
    "model = LogisticRegression(random_state=501, n_jobs=3, C=C, dual=True)\n",
    "data = gen_features(raw_data, ngram_range=ngram_range, n_features=n_features)\n",
    "print(model.fit(data['features'], data['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = gen_features(raw_test, ngram_range=ngram_range, n_features=n_features)\n",
    "sample_submission['Answer'] = model.predict_proba(test['features'])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.290918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.148062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.181124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.067910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.173589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    Answer\n",
       "0   0  0.290918\n",
       "1   1  0.148062\n",
       "2   2  0.181124\n",
       "3   3  0.067910\n",
       "4   4  0.173589"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.tsv\", sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
