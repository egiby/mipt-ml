{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def read_data(filename, labels, types, sep=None):\n",
    "    data = dict()\n",
    "    for label in labels:\n",
    "        data[label] = []\n",
    "    \n",
    "    with open(filename) as fin:\n",
    "        for line in fin:\n",
    "            keys = []\n",
    "            if sep is None:\n",
    "                keys = line.split()\n",
    "            else:\n",
    "                keys = line.split(sep)\n",
    "            \n",
    "            for key, label, ttype in zip(keys, labels, types):\n",
    "                data[label].append(ttype(key))\n",
    "            \n",
    "    data['size'] = len(data[labels[0]])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = '../../data/linear_contest1/'\n",
    "raw_data = read_data(prefix + 'linear_train.txt', ['words', 'y'], [str, int], sep=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем признаки и обрабатываем данные\n",
    "    Хеши по модулю\n",
    "    Хеш последних трех символов (логично, что окончание влияет)\n",
    "    *В одном ли регистре написана (если с большой буквы, то может и фамилия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_by_indices(data, indices):\n",
    "    new_data = dict()\n",
    "    new_data['size'] = len(indices)\n",
    "    \n",
    "    for key, feature in data.items():\n",
    "        if key == 'size':\n",
    "            continue\n",
    "        new_data[key] = np.array(data[key])[list(indices)]\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "\n",
    "def sample(data, frac, random_state):  # data must have key 'size'\n",
    "    np.random.seed(random_state)\n",
    "    indices = set()\n",
    "    N = int(data['size'] * frac)\n",
    "    \n",
    "    while len(indices) < N:\n",
    "        indices.add(np.random.randint(0, data['size']))\n",
    "    \n",
    "    return get_by_indices(data, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10140"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac = .1\n",
    "\n",
    "train_sample = sample(raw_data, frac=frac, random_state=501)\n",
    "\n",
    "train_sample['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def gen_features(sample, ngram_range=(1, 4), n_features=2 ** 20):\n",
    "    hashes = HashingVectorizer(ngram_range=ngram_range, \n",
    "                               analyzer='char', \n",
    "                               n_features=n_features).fit_transform(sample['words'])\n",
    "    new_sample = dict(sample)\n",
    "    new_sample['features'] = hashes\n",
    "    return new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': <10140x1048576 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 212631 stored elements in Compressed Sparse Row format>,\n",
       " 'size': 10140,\n",
       " 'words': array(['Аалтонен', 'Катон', 'шпиля', ..., 'прегрешениями', 'католиков',\n",
       "        'ПРЕДАНИЯМИ'], \n",
       "       dtype='<U33'),\n",
       " 'y': array([1, 1, 0, ..., 0, 0, 0])}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_features(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "def roc_auc(y, y_pred):\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_pred, y)\n",
    "    return metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "def cross_validation(model, data, n_splits=5, **kwargs):\n",
    "    score = 0.\n",
    "    for train_indices, test_indices in KFold(n_splits=n_splits).split(data['y']):\n",
    "        train = get_by_indices(data, train_indices)\n",
    "        test = get_by_indices(data, test_indices)\n",
    "        train = gen_features(train, **kwargs)\n",
    "        test = gen_features(test, **kwargs)\n",
    "        model.fit(train['features'], train['y'])\n",
    "        score += roc_auc(model.predict_proba(test['features'])[:, 1], test['y'])\n",
    "    \n",
    "    return score / n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844635776661\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# print(cross_validation(LogisticRegression(random_state=501, n_jobs=3, C=3.8, dual=True), \n",
    "#                        raw_data,\n",
    "#                        ngram_range=(1, 4)))\n",
    "\n",
    "print(cross_validation(LogisticRegression(random_state=501, n_jobs=3, C=5.0, dual=True), \n",
    "                       raw_data,\n",
    "                       ngram_range=(1, 4),\n",
    "                       n_features=262144))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 0.844921861779\n",
      "3.2 0.844989852439\n",
      "3.4 0.845033025448\n",
      "3.6 0.845045724419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "for C in np.arange(3., 5.01, 0.2):\n",
    "    print(C, cross_validation(LogisticRegression(random_state=501, n_jobs=3, C=C, dual=True), \n",
    "                              raw_data,\n",
    "                              ngram_range=(1, 4),\n",
    "                              n_features=262144))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32768 0.802397299792\n",
      "65536 0.803444985897\n",
      "131072 0.80392836637\n",
      "262144 0.804428782149\n",
      "524288 0.803693258327\n",
      "1048576 0.803800561423\n",
      "2097152 0.804000592551\n",
      "4194304 0.804250318339\n"
     ]
    }
   ],
   "source": [
    "for n_features in [2 ** i for i in range(15, 23)]:\n",
    "    print(n_features, cross_validation(LogisticRegression(random_state=501, n_jobs=3, C=3.8), \n",
    "                              train_sample,\n",
    "                              ngram_range=(1, 4),\n",
    "                              n_features=n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=3)]: Done 150 out of 150 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.81800827719452041, {'C': 2.0000000000000009, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.8183958393179217, {'C': 1.6000000000000005, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.82574306968175415, {'C': 1.3000000000000003, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.82749149731093952, {'C': 1.5000000000000004, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.84174974507011713, {'C': 1.4000000000000004, 'penalty': 'l2', 'random_state': 501})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model = LogisticRegression()\n",
    "clf = GridSearchCV(model, \n",
    "                   {\n",
    "                       'random_state': (501,), \n",
    "                       'C': np.arange(1, 6, 0.1),\n",
    "                       'penalty': ('l2',)\n",
    "                   }, \n",
    "                   n_jobs=3,\n",
    "                   scoring=make_scorer(roc_auc),\n",
    "                   verbose=1)\n",
    "\n",
    "data = gen_features(train_sample, ngram_range=(1, 4))\n",
    "clf.fit(data['features'], data['y'])\n",
    "\n",
    "print(*sorted(list(zip(clf.cv_results_['mean_test_score'], clf.cv_results_['params'])), \n",
    "              key=lambda x: x[0])[-5:], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.76156287049395088, {'C': 5.3000000000000043, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.76215475423129719, {'C': 5.5000000000000036, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.76316474013881208, {'C': 5.4000000000000039, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.76431691384592904, {'C': 1.0, 'penalty': 'l2', 'random_state': 501})\n",
      "(0.76761605604853467, {'C': 1.1000000000000001, 'penalty': 'l2', 'random_state': 501})\n"
     ]
    }
   ],
   "source": [
    "print(*sorted(list(zip(clf.cv_results_['mean_test_score'], clf.cv_results_['params'])), \n",
    "              key=lambda x: x[0])[-5:], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Для отправки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prefix = '../../data/linear_contest1/'\n",
    "raw_data = read_data(prefix + 'linear_train.txt', ['words', 'y'], [str, int], sep=', ')\n",
    "raw_test = read_data(prefix + 'linear_test.txt', ['words'], [str])\n",
    "sample_submission = pd.read_csv(prefix + 'linear_ans_example.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=5.3, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=3,\n",
      "          penalty='l2', random_state=501, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "CPU times: user 6.67 s, sys: 16.7 ms, total: 6.68 s\n",
      "Wall time: 6.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# M = 25\n",
    "# M = 15\n",
    "# model = RandomForestClassifier(n_estimators=150, n_jobs=3, random_state=501)\n",
    "# model = SVC(probability=True, random_state=501)\n",
    "C = 3.8\n",
    "ngram_range = (1, 4)\n",
    "n_features = 2 ** 20\n",
    "model = LogisticRegression(random_state=501, n_jobs=3, C=5.3, dual=True)\n",
    "data = gen_features(raw_data, ngram_range=ngram_range, n_features=n_features)\n",
    "print(model.fit(data['features'], data['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gen_features(raw_test, ngram_range=ngram_range, n_features=n_features)\n",
    "sample_submission['Answer'] = model.predict_proba(test['features'])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.tsv\", sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
